[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Inha_Accident_Report",
    "section": "",
    "text": "1 인하대학교 강간 살인 사건 언론 재현 보고서"
  },
  {
    "objectID": "index.html#들어가기-앞서",
    "href": "index.html#들어가기-앞서",
    "title": "Inha_Accident_Report",
    "section": "1.1 들어가기 앞서",
    "text": "1.1 들어가기 앞서\n본 문서는 지난 2022년 7월 15일, 인하대학교 재학생 강간살인 사건의 언론 재현 수준을 분석한 보고서이다."
  },
  {
    "objectID": "index.html#데이터-수집",
    "href": "index.html#데이터-수집",
    "title": "Inha_Accident_Report",
    "section": "1.2 데이터 수집",
    "text": "1.2 데이터 수집\n먼저 해당 사건 발생일 기준 3개월 간의 뉴스 기사 데이터를 수집하였다.해당 기간 이후의 기사는 대체적으로 본 사건과 관련이 없는 기사가 많았다. 이에, 총 3개월 치의 기사만 수집하였다.\n기사는 빅카인즈(BigKinds)를 통해 수집하였다. 포털 사이트의 기사를 크롤링을 하는 방법도 있으나, 포털 뉴스 특성상 기사가 중복된 내용이거나 지나친 편향성을 지닌 기사가 많아, 본 분석에선 빅카인즈에서 데이터를 별도로 수집하는 방식을 선택했다.\n또한 언론의 어젠다를 분석하는데 있어 주요 신문사들의 보도를 보는 것이 좋다고 판단하여 총 10개의 언론사(“세계일보”, “문화일보”, “경향신문”, “동아일보”, “한겨레”, “서울신문”,“한국일보”,“중앙일보”, “국민일보”,“조선일보”)의 기사를 선별하여 데이터를 수집했다.\n분석 방법 및 결과는 앞으로의 문서에서 다룬다."
  },
  {
    "objectID": "inha_clustering.html#개요",
    "href": "inha_clustering.html#개요",
    "title": "2  Clustering analysis을 중심으로",
    "section": "2.1 개요",
    "text": "2.1 개요\n본 내용은 인하대학교 사건 기사를 분석한 내용을 담고 있다.\n먼저, 가장 보편적으로 기사 분석에 가장 많이 사용하는 방법인 Clustering Analysis 기법을 사용하여, 분석을 진행했다.\n분석 언어는 Python을 사용했으며, 군집 분석은 Scikit-Learn의 KMeans() 함수를 활용하여 분석을 진행했다.\n깊게 존재하는 의미 연결망 분석 및 담론 분석은 이후 보고서에서 작성하였다."
  },
  {
    "objectID": "inha_clustering.html#데이터-현황-및-필터링",
    "href": "inha_clustering.html#데이터-현황-및-필터링",
    "title": "2  Clustering analysis을 중심으로",
    "section": "2.2 데이터 현황 및 필터링",
    "text": "2.2 데이터 현황 및 필터링\n먼저 수집한 기사들의 언론사 구성 빈도는 다음과 같다.\n\npress = bkp.press_counter(news_df)\nsns.barplot(data = press, x = \"기사\", y = \"언론사\")\n\n&lt;Axes: xlabel='기사', ylabel='언론사'&gt;\n\n\n\n\n\n\n해당 데이터 중 포토 기사는 내용적 측면에서 데이터 분석이 매우 어렵다. 이에 포토 기사는 본 분석에서 제외하기로 결정했다.\n\nfilt = news_df[news_df['제목'].str.contains('포토')].index\nnews_df.drop(filt, inplace=True)\nnews_df.reset_index(drop = True, inplace = True)"
  },
  {
    "objectID": "inha_clustering.html#키워드-빈도-분석",
    "href": "inha_clustering.html#키워드-빈도-분석",
    "title": "2  Clustering analysis을 중심으로",
    "section": "2.3 키워드 빈도 분석",
    "text": "2.3 키워드 빈도 분석\n키워드 빈도 분석을 진행하였다. 단어 전체의 키워드를 추출한 후, 이를 워드클라우드로 변환하여 분석하였다.\n분석 결과는 다음과 같다.\n\nwc = WordCloud(font_path = 'malgun',\n    width = 500,\n    height = 500,\n    background_color='white').generate_from_frequencies(key_words.set_index('단어').to_dict()[\"빈도\"])\n\n\nplt.figure(figsize = (8, 8))\nplt.imshow(wc)\nplt.axis('off')\nplt.show()\n\n\n\n\n\n다음은 언론사 별 단어 빈도 분석 결과이다. 본 분석은 보수 언론(조선, 중앙, 동아)와 진보 언론(한겨례, 경향) 간의 차이를 확인하고자 진행하였다.\n분석은 위의 절차와 동일한 방법으로 키워드 변환 이후 워드클라우드로 시각화했다.\n분석 결과는 다음과 같다.\n조선일보\n\nbkp.keywords_wordcloud(news_df, '조선일보')\n\n\n\n\n\n중앙일보\n\nbkp.keywords_wordcloud(news_df, '중앙일보')\n\n\n\n\n\n동아일보\n\nbkp.keywords_wordcloud(news_df, '동아일보')\n\n\n\n\n\n한겨례\n\nbkp.keywords_wordcloud(news_df, '한겨레')\n\n\n\n\n\n경향신문\n\nbkp.keywords_wordcloud(news_df, '경향신문')"
  },
  {
    "objectID": "inha_clustering.html#dtm-구축",
    "href": "inha_clustering.html#dtm-구축",
    "title": "2  Clustering analysis을 중심으로",
    "section": "2.4 DTM 구축",
    "text": "2.4 DTM 구축\n우선 문서 데이터의 분석을 원활히 하기 위해 DTM(Document Term Matrix)을 구축하였다.\nDTM은 문서에서 키워드만 추출하여 list에 담은 뒤, Scikit-Learn의 CounterVCtorizer를 활용하여 word vector를 생성하였다. 그 후, TfidfTransformer를 통해 문서 내 단어 중요도를 반영하였다.\n\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\nfrom sklearn.pipeline import Pipeline\n\ntext = news_df['키워드']\n\npipeline = Pipeline([\n    ('vect', CountVectorizer()),\n    ('tfidf', TfidfTransformer()),\n])        \nvec = pipeline.fit_transform(text).toarray()\n\nDTM 생성 후, 모델에서의 분석 정확도 고려를 위해, Nomalizer로 스케일링을 진행하였다.\n\nfrom sklearn.preprocessing import Normalizer\n\nnor = Normalizer()\nnorvec = nor.fit_transform(vec)\n\n다음은 DTM을 t-SNE기법으로 차원을 축소하여 시각화한 형태이다.\n전반적으로 문서가 흩어져 있는 양상을 보여, 군집 간의 밀집 정도 파악은 다소 어려워보인다. 아무래도 문서의 양이 절대적으로 적다보니, 문서 간 군집 형성 정도를 확인하기 어려운 부분이 있다.\n\nfrom sklearn.manifold import TSNE\n\ntsne = TSNE(n_components=2, learning_rate=400).fit_transform(norvec)\n\ntsne_df = pd.DataFrame(tsne, columns = ['component 0', 'component 1'])\n\nplt.scatter(tsne_df['component 0'], tsne_df['component 1'], color = 'orange')\n\nplt.xlabel('component 0')\nplt.ylabel('component 1')\nplt.legend()\nplt.show()\n\nNo artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument."
  },
  {
    "objectID": "inha_clustering.html#k-means-clustering",
    "href": "inha_clustering.html#k-means-clustering",
    "title": "2  Clustering analysis을 중심으로",
    "section": "2.5 K-means Clustering",
    "text": "2.5 K-means Clustering\n본격적으로 데이터 분석을 진행하고자 문서 군집화를 진행하였다.\n방법의 경우, K-means Clustering으로 진행하였다. 문서의 양이 많지 않은 데다가 분포가 고르지 못한 경향이 있어, K-means Clustering이 이에 가장 적합한 분석 방법이라고 판단했다.\n먼저, K-Means Clustering을 시행하기 위해 최적 군집 갯수를 유추하였다. Elbow method를 통해 분석을 진행하였으며, 이를 통해 최적 군집의 갯수는 12개로 유추하였다.\n\nfrom sklearn.cluster import KMeans\nfrom yellowbrick.cluster import KElbowVisualizer\n\nvzr = KElbowVisualizer(KMeans(max_iter=1000, random_state=10), k=(2, 20))\nvzr.fit(norvec)\nvzr.poof()\n\n\n\n\n&lt;Axes: title={'center': 'Distortion Score Elbow for KMeans Clustering'}, xlabel='k', ylabel='distortion score'&gt;\n\n\n최적 군집 갯수를 기점으로 실루엣 계수를 분석하였다.\n실루엣 계수는 군집 간의 유사도를 수치적으로 확인하는 방법이다.\n\nfrom yellowbrick.cluster import SilhouetteVisualizer\n\nkmeans= KMeans(n_clusters=12, max_iter=1000, random_state=10) #최적 Topic 개수 12개를 기점으로 진행\nvisualizer = SilhouetteVisualizer(kmeans, colors='yellowbrick')\n\nvisualizer.fit(norvec)\nvisualizer.show()\n\n\n\n\n&lt;Axes: title={'center': 'Silhouette Plot of KMeans Clustering for 635 Samples in 12 Centers'}, xlabel='silhouette coefficient values', ylabel='cluster label'&gt;\n\n\n전반적으로 계수가 높지 않았다. 다만, 텍스트 데이터 특성상 실루엣 계수가 낮아도 의미적으로는 문제가 없는 경우가 다소 있어,’ k 값은 elbow method의 결과인 12로 진행하기로 결정하였다.\n\nkmeans.fit(norvec)\n\nKMeans(max_iter=1000, n_clusters=12, random_state=10)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.KMeansKMeans(max_iter=1000, n_clusters=12, random_state=10)\n\n\n군집 별 기사 갯수는 다음과 같다.\n\nlabels = kmeans.labels_\n\ntopic_df = news_df[['언론사', '제목', '키워드']]\n\ntopic_df['군집'] = labels\n\ntopic_df.groupby('군집').size()\n\n군집\n0      34\n1      14\n2      59\n3      17\n4     103\n5      75\n6      42\n7      40\n8     186\n9      29\n10     16\n11     20\ndtype: int64\n\n\n\n군집 내 기사들의 내용을 분석한 결과, 다음과 같이 클러스터링이 진행됐다.\n\ntopic_df.loc[topic_df['군집']==0, '군집'] = '경제'\ntopic_df.loc[topic_df['군집']==1, '군집'] = '리멤버 0715'\ntopic_df.loc[topic_df['군집']==2, '군집'] = '인하대 사건 그 이후'\ntopic_df.loc[topic_df['군집']==3, '군집'] = '인하대 입시'\ntopic_df.loc[topic_df['군집']==4, '군집'] = '인하대 사건 조사보도'\ntopic_df.loc[topic_df['군집']==5, '군집'] = '가해자 재판'\ntopic_df.loc[topic_df['군집']==6, '군집'] = '젠더 이슈'\ntopic_df.loc[topic_df['군집']==7, '군집'] = '가해자 체포'\ntopic_df.loc[topic_df['군집']==8, '군집'] = '관련 없는 기사'\ntopic_df.loc[topic_df['군집']==9, '군집'] = '학교 측 가해자 징계'\ntopic_df.loc[topic_df['군집']==10, '군집'] = '인하대 총장'\ntopic_df.loc[topic_df['군집']==11, '군집'] = '부고'\n\n다음 결과 중 본 사건과 관련 없는 기사는 별도로 필터링한 상태로, 데이터를 추출하였다.\n해당 데이터를 통해 의미 연결망 분석을 진행하였으며, 해당 내용은 “2. 의미연결망 분석을 중심으로” 편에서 다루기로 한다.\n\nfilter_list = ['경제', '인하대 입시', '관련 없는 기사', '인하대 총장', '부고']\ninha_df = topic_df[~topic_df['군집'].isin(filter_list)]\ninha_df.reset_index(drop = True, inplace = True)"
  },
  {
    "objectID": "inha_network.html#개요",
    "href": "inha_network.html#개요",
    "title": "3  Network Analysis을 중심으로",
    "section": "3.1 개요",
    "text": "3.1 개요\n본 문서는 1편에서 진행한 k-means clustering method로 추출한 기사를 군집 별 데이터 분석 및 단어 빈도 분석, 의미연결망 분석을 진행한 내용을 담고 있으며, 분석 도구는 R로 진행하였다. 아무래도 의미연결망 분석이나 빈도 시각화에 있어선 아직까지 Python보다는 R이 더 우수한 경향이 있기에, R로 변경하여 분석을 이어갔다.\n분석에 사용된 총 기사의 갯수는 다음과 같다.\n\n\n[1] 362   4"
  },
  {
    "objectID": "inha_network.html#단어-분석",
    "href": "inha_network.html#단어-분석",
    "title": "3  Network Analysis을 중심으로",
    "section": "3.2 단어 분석",
    "text": "3.2 단어 분석\n먼저 기사에 사용된 단어를 분석한 결과, 총 4190개로 나타났다.\n\n\n[1] 4190    2\n\n\n상위 15개의 주요 단어를 추출한 결과는 다음과 같다.\n\n\n# A tibble: 15 × 2\n   단어       n\n   &lt;chr&gt;  &lt;int&gt;\n 1 인하대  1551\n 2 경찰    1244\n 3 사건    1157\n 4 혐의    1143\n 5 피해자  1046\n 6 건물     973\n 7 성폭행   963\n 8 추락     943\n 9 캠퍼스   704\n10 사망     633\n11 발견     548\n12 대학     493\n13 여성     484\n14 학교     476\n15 조사     446"
  },
  {
    "objectID": "inha_network.html#보도-빈도-분석",
    "href": "inha_network.html#보도-빈도-분석",
    "title": "3  Network Analysis을 중심으로",
    "section": "3.3 보도 빈도 분석",
    "text": "3.3 보도 빈도 분석\n언론사 별 보도 빈도는 다음과 같다.\n\ninha %&gt;% \n  group_by(언론사) %&gt;% \n  tally() %&gt;% \n  arrange(desc(n)) %&gt;% gt() %&gt;% tab_header('언론사 별 보도 빈도') %&gt;% \n  cols_label(언론사 = \"언론사\", n = '빈도')\n\n\n\n\n\n  \n    \n      언론사 별 보도 빈도\n    \n    \n    \n      언론사\n      빈도\n    \n  \n  \n    세계일보\n81\n    서울신문\n45\n    국민일보\n40\n    조선일보\n36\n    동아일보\n35\n    중앙일보\n35\n    경향신문\n26\n    한겨레\n24\n    한국일보\n24\n    문화일보\n16\n  \n  \n  \n\n\n\n\n보도 빈도만 두고 본 결과, 3개월의 기간 동안 해당 어젠다를 중점적으로 다룬 언론사는 세계일보였다. 그 외에는 전반적으로 비슷한 수준의 보도를 진행하였다."
  },
  {
    "objectID": "inha_network.html#군집-별-보도-분석",
    "href": "inha_network.html#군집-별-보도-분석",
    "title": "3  Network Analysis을 중심으로",
    "section": "3.4 군집 별 보도 분석",
    "text": "3.4 군집 별 보도 분석\n이전에 기사 필터링을 진행하여 나타난 군집들의 양상을 근거로 언론사들의 보도 스탠스를 유추하여 보았다.\n군집 별 기사 빈도는 다음과 같다.\n\ninha %&gt;% \n  group_by(군집) %&gt;% \n  tally() %&gt;% \n  arrange(desc(n)) %&gt;% gt() %&gt;% tab_header('군집 별 기사 빈도') %&gt;% \n  cols_label(군집 = \"군집\", n = '빈도')\n\n\n\n\n\n  \n    \n      군집 별 기사 빈도\n    \n    \n    \n      군집\n      빈도\n    \n  \n  \n    인하대 사건 조사보도\n103\n    가해자 재판\n75\n    인하대 사건 그 이후\n59\n    젠더 이슈\n42\n    가해자 체포\n40\n    학교 측 가해자 징계\n29\n    리멤버 0715\n14\n  \n  \n  \n\n\n\n\n이들 중 언론사의 어젠다 설정 방향을 유추할 수 있는 군집인 “인하대 사건 조사보도”, “인하대 사건 그 이후”, “젠더 이슈”를 추출하여 언론사 별 보도 비율을 확인하였다.\n먼저 인하대 사건 조사보도 군집에 해당하는 기사들의 언론사 구성 비율이다\n\ninha %&gt;% \n  filter(군집 == '인하대 사건 조사보도') %&gt;% \n  group_by(언론사) %&gt;% \n  tally() %&gt;% \n  arrange(desc(n)) %&gt;% \n  ggplot(aes(x = \"\", y = n, fill = 언론사))+\n  geom_bar(width = 1, stat = 'identity', color = \"white\")+\n  theme(axis.text.y = element_blank(),axis.ticks = element_blank(), legend.text = element_text(size = 9))+\n  geom_text(aes(label = paste(round(n/sum(n)*100, 2),\"%\")),\n            position = position_stack(vjust = 0.6),\n            check_overlap = TRUE,\n            color = 'white')+\n  coord_polar('y', start = 0)+\n  xlab(\"\")+\n  ylab(\"\")\n\n\n\n\n그 다음 인하대 사건 그 이후 군집에 해당하는 기사들의 언론사 구성 비율이다\n\ninha %&gt;% \n  filter(군집 == '인하대 사건 그 이후') %&gt;% \n  group_by(언론사) %&gt;% \n  tally() %&gt;% \n  arrange(desc(n)) %&gt;% \n  ggplot(aes(x = \"\", y = n, fill = 언론사))+\n  geom_bar(width = 1, stat = 'identity', color = \"white\")+\n  theme(axis.text.y = element_blank(),axis.ticks = element_blank(), legend.text = element_text(size = 9))+\n  geom_text(aes(label = paste(round(n/sum(n)*100, 2),\"%\")),\n            position = position_stack(vjust = 0.5),\n            check_overlap = TRUE,\n            color = 'white')+\n  coord_polar('y', start = 0)+\n  xlab(\"\")+\n  ylab(\"\")\n\n\n\n\n마지막으로 젠더 이슈에 대한 기사들의 언론사 구성 비율이다.\n\ninha %&gt;% \n  filter(군집 == '젠더 이슈') %&gt;% \n  group_by(언론사) %&gt;% \n  tally() %&gt;% \n  arrange(desc(n)) %&gt;%\n  ggplot(aes(x = \"\", y = n, fill = 언론사))+\n  geom_bar(width = 1, stat = 'identity', color = \"white\")+\n  theme(axis.text.y = element_blank(),axis.ticks = element_blank(), legend.text = element_text(size = 9))+\n  geom_text(aes(label = paste(round(n/sum(n)*100, 2),\"%\")),\n            position = position_stack(vjust = 0.5),\n            check_overlap = TRUE,\n            color = 'white')+\n  coord_polar('y', start = 0)+\n  xlab(\"\")+\n  ylab(\"\")"
  },
  {
    "objectID": "inha_network.html#언론사-별-단어-분석",
    "href": "inha_network.html#언론사-별-단어-분석",
    "title": "3  Network Analysis을 중심으로",
    "section": "3.5 언론사 별 단어 분석",
    "text": "3.5 언론사 별 단어 분석\n언론사 별로 주로 사용한 단어는 다음과 같다.\n\ninha.words %&gt;% \n  slice_max(n, n = 10) %&gt;%\n  ggplot(aes(x = n, y = reorder_within(단어, n, 언론사), fill = 언론사)) +\n  geom_col(show.legend = F) +\n  facet_wrap(~ 언론사, scales = 'free') + \n  scale_y_reordered()+\n  xlab(\"\")+\n  ylab(\"\")\n\n\n\n\ntf-idf를 활용하여 단어 별 상대 빈도를 도출했다.\n상대 빈도 분석 결과는 다음과 같다.\n\ntfidf.df %&gt;% \n  slice_max(score, n = 5) %&gt;%\n  ggplot(aes(x = score, y = reorder_within(단어, score, 언론사), fill = 언론사)) +\n  geom_col(show.legend = F) +\n  facet_wrap(~ 언론사, scales = 'free') + \n  scale_y_reordered()+\n  xlab(\"\")+\n  ylab(\"\")"
  },
  {
    "objectID": "inha_network.html#press-network-analysis",
    "href": "inha_network.html#press-network-analysis",
    "title": "3  Network Analysis을 중심으로",
    "section": "3.6 Press Network Analysis",
    "text": "3.6 Press Network Analysis\n먼저, 언론사 간 네트워크 분석을 실시했다.\n본 분석은 tf-idf로 상대 빈도 분석을 진행한 데이터를 기준으로, 공동으로 등장하는 단어에 기반하여 네트워크 분석을 실시했다.\n분석 결과의 정확성 확보를 위해 한국어가 아닌 단어들(영문, 숫자 등)은 분석에서 제외했다.\n또한 네트워크 분석과 함께 군집화를 진행했다. 문서 간의 유사도가 높은 네트워크를 중심으로 군집을 형성했다. 유사도 판정 기준은 분석에 사용한 프로그래밍 언어인 R의 유사도 검정 기능을 활용했다.\n네트워크 분석 결과는 다음과 같다.\n\nplot(clust, press.nt)"
  },
  {
    "objectID": "inha_network.html#sementic-network-analysis",
    "href": "inha_network.html#sementic-network-analysis",
    "title": "3  Network Analysis을 중심으로",
    "section": "3.7 Sementic Network Analysis",
    "text": "3.7 Sementic Network Analysis\n마지막으로 단어 간의 의미 연결망 분석을 실시했다. 네트워크 분석의 경우, 데이터를 통해 동시 출현 단어 행렬을 형성하고, 이를 토대로 quenteda를 활용하여 네트워크 분석을 시도했다.\n분석 결과는 다음과 같다.\n\ntextplot_network(fc, \n                 min_freq = 2, \n                 edge_alpha = 0.5, \n                 edge_color = \"blue\",\n                 vertex_size = size,\n                 edge_size = 0.5)"
  }
]