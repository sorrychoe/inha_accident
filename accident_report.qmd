---
title: "인하대학교 강간살인 사건 언론 재현 분석"
author: "sorrychoe"
format: 
  html: 
    smooth-scroll: true
editor: visual
execute: 
  echo: true
  eval: true
---

```{r setup, include=F, message=F}
library(tidyverse)
library(plotly)
library(tidytext)
library(tidylo)
library(gt) 
library(igraph)
library(quanteda)
library(quanteda.textplots)
library(readxl)


inha <- read_excel("./inha_topic.xlsx")
```

<hr/>

## 개요

지난 2022년 7월 15일, 인하대학교 재학생 강간살인 사건의 언론 재현 수준을 분석한 보고서이다. 

먼저 해당 사건 발생일 기준 3개월 간의 뉴스 기사 데이터를 수집하였다.해당 기간 이후의 기사는 
대체적으로 본 사건과 관련이 없는 기사가 많았다. 이에, 총 3개월 치의 기사만 수집하였다. 

기사는 빅카인즈(BigKinds)를 통해 수집하였다. 포털 사이트의 기사를 크롤링을 하는 방법도 있으나,
포털 뉴스 특성상 기사가 중복된 내용이거나, 지나친 편향성을 지닌 기사가 많아, 해당 내용은 본 분석에서 제외하였다.

또한 언론의 어젠다를 분석하는데 있어 주요 신문사들의 보도를 보는 것이 좋다고 판단하여 총 10개의 언론사("세계일보", "문화일보", "경향신문", "동아일보", "한겨레", "서울신문","한국일보","중앙일보", "국민일보","조선일보")의 기사를 선별하여 데이터를 수집했다.

추가로, 7월 15일부터 10월 15일의 기간에 보도된 기사 중, 해당 사건과 관련 없는 기사를 필터링하였다. 
기사 필터링은 Python 환경에서 진행하였으며, 해당 내용 자체만으로도 내용이 많아, 별도의 문서에서 다루기로 하였다.

분석에 사용된 총 기사의 갯수는 다음과 같다.
```{r, echo = F}
dim(inha)
```

<hr/>

# 단어 분석

먼저 기사에 사용된 단어를 분석한 결과, 총 4190개로 나타났다.
```{r, echo = F}
inha %>% 
  select(키워드) %>% 
  rowid_to_column() %>%
  unnest_tokens(
    input = "키워드",
    output = "단어") %>% 
  filter(nchar(단어) >= 2) %>% 
  count(`단어`, sort = TRUE) -> words

dim(words) #4190
```

상위 15개의 주요 단어를 추출한 결과는 다음과 같다. 
```{r, echo = F}
words %>% head(15) #counter
```

<hr/>

## 보도 빈도 분석

언론사 별 보도 빈도는 다음과 같다.
```{r}
inha %>% 
  group_by(언론사) %>% 
  tally() %>% 
  arrange(desc(n)) %>% gt() %>% tab_header('언론사 별 보도 빈도') %>% 
  cols_label(언론사 = "언론사", n = '빈도')
```

보도 빈도만 두고 본 결과, 3개월의 기간 동안 해당 어젠다를 중점적으로 다룬 언론사는 세계일보였다.
그 외에는 전반적으로 비슷한 수준의 보도를 진행하였다.

<hr/>

## 군집 별 보도 분석

이전에 기사 필터링을 진행하여 나타난 군집들의 양상을 근거로 언론사들의 보도 스탠스를 유추하여 보았다.

군집 별 기사 빈도는 다음과 같다.
```{r}
inha %>% 
  group_by(군집) %>% 
  tally() %>% 
  arrange(desc(n)) %>% gt() %>% tab_header('군집 별 기사 빈도') %>% 
  cols_label(군집 = "군집", n = '빈도')
```

이들 중 언론사의 어젠다 설정 방향을 유추할 수 있는 군집인 "인하대 사건 조사보도", "인하대 사건 그 이후", "젠더 이슈"를 추출하여
언론사 별 보도 비율을 확인하였다.

먼저 인하대 사건 조사보도 군집에 해당하는 기사들의 언론사 구성 비율이다
```{r}
inha %>% 
  filter(군집 == '인하대 사건 조사보도') %>% 
  group_by(언론사) %>% 
  tally() %>% 
  arrange(desc(n)) %>% 
  ggplot(aes(x = "", y = n, fill = 언론사))+
  geom_bar(width = 1, stat = 'identity', color = "white")+
  theme(axis.text.y = element_blank(),axis.ticks = element_blank(), legend.text = element_text(size = 9))+
  geom_text(aes(label = paste(round(n/sum(n)*100, 2),"%")),
            position = position_stack(vjust = 0.6),
            check_overlap = TRUE,
            color = 'white')+
  coord_polar('y', start = 0)+
  xlab("")+
  ylab("")
```

그 다음 인하대 사건 그 이후 군집에 해당하는 기사들의 언론사 구성 비율이다
```{r}
inha %>% 
  filter(군집 == '인하대 사건 그 이후') %>% 
  group_by(언론사) %>% 
  tally() %>% 
  arrange(desc(n)) %>% 
  ggplot(aes(x = "", y = n, fill = 언론사))+
  geom_bar(width = 1, stat = 'identity', color = "white")+
  theme(axis.text.y = element_blank(),axis.ticks = element_blank(), legend.text = element_text(size = 9))+
  geom_text(aes(label = paste(round(n/sum(n)*100, 2),"%")),
            position = position_stack(vjust = 0.5),
            check_overlap = TRUE,
            color = 'white')+
  coord_polar('y', start = 0)+
  xlab("")+
  ylab("")

```


마지막으로 젠더 이슈에 대한 기사들의 언론사 구성 비율이다.
```{r}
inha %>% 
  filter(군집 == '젠더 이슈') %>% 
  group_by(언론사) %>% 
  tally() %>% 
  arrange(desc(n)) %>%
  ggplot(aes(x = "", y = n, fill = 언론사))+
  geom_bar(width = 1, stat = 'identity', color = "white")+
  theme(axis.text.y = element_blank(),axis.ticks = element_blank(), legend.text = element_text(size = 9))+
  geom_text(aes(label = paste(round(n/sum(n)*100, 2),"%")),
            position = position_stack(vjust = 0.5),
            check_overlap = TRUE,
            color = 'white')+
  coord_polar('y', start = 0)+
  xlab("")+
  ylab("")
```

<hr/>

## 언론사 별 단어 분석

언론사 별로 주로 사용한 단어는 다음과 같다.

```{r, echo = F}
inha %>% 
  select(언론사, 키워드) %>% 
  rowid_to_column() %>%
  unnest_tokens(
    input = "키워드",
    output = "단어") %>% 
  group_by(언론사) %>% 
  filter(nchar(단어) >= 2) %>% 
  count(`단어`, sort = TRUE)-> inha.words

reorder_within <- function(x, by, within, fun = sum, sep = "___", ...) {
  new_x <- paste(x, within, sep = sep)
  stats::reorder(new_x, by, FUN = fun)
}
```

```{r}
inha.words %>% 
  slice_max(n, n = 10) %>%
  ggplot(aes(x = n, y = reorder_within(단어, n, 언론사), fill = 언론사)) +
  geom_col(show.legend = F) +
  facet_wrap(~ 언론사, scales = 'free') + 
  scale_y_reordered()+
  xlab("")+
  ylab("")
```

표로 변환한 결과는 다음과 같다.
```{r, echo = F, message=F}
texts <- split(inha.words, inha.words$언론사)

top15 <-function(x){
  x <- x %>% head(20)
  return(x)
}

num = 1
for (k in texts){
  k <- top15(k)
  if (num == 1){
    words = k
    num = 2
  }else{
  words <- cbind(words, k)
  }
}

varnames <- c('언론사', '단어', 'n')

names(words)[1:ncol(words)]<- paste0(varnames,"_",1:30)

words %>% 
  select(!starts_with('언론사')) %>% 
  gt() %>% 
  tab_options(container.width = 300, container.height = 300) %>%
  tab_header('언론사 별 단어 빈도') %>% 
  tab_spanner(label = "경향신문",
              columns = 1:2) %>% 
  tab_spanner(label = "국민일보", 
              columns = 3:4)%>% 
  tab_spanner(label = "동아일보", 
              columns = 5:6)%>%
  tab_spanner(label = "문화일보", 
              columns = 7:8)%>% 
  tab_spanner(label = "서울신문", 
              columns = 9:10)%>%
  tab_spanner(label = "세계일보", 
              columns = 11:12)%>% 
  tab_spanner(label = "조선일보", 
              columns = 13:14)%>%
  tab_spanner(label = "중앙일보", 
              columns = 15:16)%>%
  tab_spanner(label = "한겨례", 
              columns = 17:18)%>%
  tab_spanner(label = "한국일보", 
              columns = 19:20)%>% 
  cols_label(
    단어_2 = "단어",
    n_3 = "빈도",
    단어_5 = "단어",
    n_6 = "빈도",
    단어_8 = "단어",
    n_9 = "빈도",
    단어_11 = "단어",
    n_12 = "빈도",
    단어_14 = "단어",
    n_15 = "빈도",
    단어_17 = "단어",
    n_18 = "빈도",
    단어_20 = "단어",
    n_21 = "빈도",
    단어_23 = "단어",
    n_24 = "빈도",
    단어_26 = "단어",
    n_27 = "빈도",
    단어_29 = "단어",
    n_30 = "빈도") -> press.word.counter

press.word.counter %>% 
  tab_options(table.font.size = 5, data_row.padding = px(1), 
    summary_row.padding = px(1), grand_summary_row.padding = px(1), 
    footnotes.padding = px(1), source_notes.padding = px(1), 
    row_group.padding = px(1))
```

상대 빈도를 분석한 결과는 다음과 같다.

상대 빈도 분석은 tf-idf로 진행했다.
```{r, echo = F, message=F}

inha.words %>%
  bind_tf_idf(document = 언론사, term = 단어, n = n) %>% 
  filter(grepl("[가-힣]", 단어)) %>% 
  mutate(score = round(tf_idf * 1000, 3)) %>% 
  arrange(-score) -> tfidf.df
```

```{r}
tfidf.df %>% 
  slice_max(score, n = 5) %>%
  ggplot(aes(x = score, y = reorder_within(단어, score, 언론사), fill = 언론사)) +
  geom_col(show.legend = F) +
  facet_wrap(~ 언론사, scales = 'free') + 
  scale_y_reordered()+
  xlab("")+
  ylab("")
```

표로 변환한 결과는 다음과 같다.
```{r, echo = F, message=F}

texts.tfidf <- split(tfidf.df, tfidf.df$언론사)

num = 1
for (k in texts.tfidf){
  k <- k %>% select(언론사, 단어, n, score)
  k <- top15(k)
  if (num == 1){
    words.tfidf = k
    num = 2
  }else{
    words.tfidf <- cbind(words.tfidf, k)
  }
}

varnames.tfidf<- c('언론사', '단어', '빈도', 'tfidf')

names(words.tfidf)[1:ncol(words.tfidf)]<- paste0(varnames.tfidf,"_",1:40)

words.tfidf %>% 
  select(!starts_with('언론사') & !starts_with('빈도')) %>% 
  gt() %>% 
  tab_header('언론사 별 단어 상대 빈도') %>% 
  tab_spanner(label = "경향신문",
              columns = 1:2) %>% 
  tab_spanner(label = "국민일보", 
              columns = 3:4)%>% 
  tab_spanner(label = "동아일보", 
              columns = 5:6)%>%
  tab_spanner(label = "문화일보", 
              columns = 7:8)%>% 
  tab_spanner(label = "서울신문", 
              columns = 9:10)%>%
  tab_spanner(label = "세계일보", 
              columns = 11:12)%>% 
  tab_spanner(label = "조선일보", 
              columns = 13:14)%>%
  tab_spanner(label = "중앙일보", 
              columns = 15:16)%>%
  tab_spanner(label = "한겨례", 
              columns = 17:18)%>%
  tab_spanner(label = "한국일보", 
              columns = 19:20)%>% 
  cols_label(
    단어_2 = "단어",
    tfidf_4 = "tfidf",
    단어_6 = "단어",
    tfidf_8 = "tfidf",
    단어_10 = "단어",
    tfidf_12 = "tfidf",
    단어_14 = "단어",
    tfidf_16 = "tfidf",
    단어_18 = "단어",
    tfidf_20 = "tfidf",
    단어_22 = "단어",
    tfidf_24 = "tfidf",
    단어_26 = "단어",
    tfidf_28 = "tfidf",
    단어_30 = "단어",
    tfidf_32 = "tfidf",
    단어_34 = "단어",
    tfidf_36 = "tfidf",
    단어_38 = "단어",
    tfidf_40 = "tfidf") -> press.tfidf.counter

press.tfidf.counter %>% 
  tab_options(table.font.size = 5, data_row.padding = px(1), 
    summary_row.padding = px(1), grand_summary_row.padding = px(1), 
    footnotes.padding = px(1), source_notes.padding = px(1), 
    row_group.padding = px(1))
```

<hr/>

## Press Network Analysis

```{r, include=F}
tfidf.df %>%
  filter(grepl("[가-힣]", 단어)) %>% 
  group_by(언론사) %>%
  slice_max(score, n = 15) -> dtm.df
```

```{r}
dtm <- t(table(dtm.df[1:2]))
press <- crossprod(dtm)
diag(press) <- 0
dtm <- as.matrix(press)

press.nt <- graph_from_adjacency_matrix(dtm, mode="undirected", weighted=TRUE)
clust <- cluster_walktrap(press.nt)

plot(clust, press.nt)
```

<hr/>

## Sementic Network Analysis

```{r}
#| warning: false

com <- table(dtm.df[1:2])
com <- crossprod(com)
diag(com) <- 0
com<- as.data.frame(com)

dfm <- as.dfm(com)
fc<- fcm(dfm)

size = log(colSums(fc)) / max(log(colSums(fc))) * 5

options(ggrepel.max.overlaps = 19)

textplot_network(fc, 
                 min_freq = 2, 
                 edge_alpha = 0.5, 
                 edge_color = "blue",
                 vertex_size = size,
                 edge_size = 0.5)
```
